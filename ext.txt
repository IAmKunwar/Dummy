def report_perf(optimizer, X, y ,title, callbacks=None):
    start = time()
    if callbacks:
        optimizer.fit(X, y, callback=callbacks)
    else:
        optimizer.fit(X, y)
    d=pd.DataFrame(optimizer.cv_results_)
    best_score = optimizer.best_score_
    best_score_std = d.iloc[optimizer.best_index_].std_test_score
    best_params = optimizer.best_params_
    print((title + " took %.2f seconds,  candidates checked: %d, best CV score: %.3f "
           +u"\u00B1"+" %.3f") % (time() - start, 
                                  len(optimizer.cv_results_['params']),
                                  best_score,
                                  best_score_std))    
#     print('eval_set score ',optimizer.score(X_test,y_test))
    print('Best parameters:')
    pprint.pprint(best_params)
    return best_params


# Initializing a CatBoostClassifier
reg = xgb.XGBRegressor(
        n_jobs = 1,
        objective = 'reg:linear',
        eval_metric = 'rmse',
        silent=1,
        tree_method='approx',
        eval_set = eval_set
    )


# Defining your search space
search_spaces = {'learning_rate': (0.01, 1.0, 'log-uniform'),
        'min_child_weight': (0, 10),
        'max_depth': (0, 50),
        'max_delta_step': (0, 20),
        'subsample': (0.01, 1.0, 'uniform'),
        'colsample_bytree': (0.01, 1.0, 'uniform'),
        'colsample_bylevel': (0.01, 1.0, 'uniform'),
        'reg_lambda': (1e-9, 1000, 'log-uniform'),
        'reg_alpha': (1e-9, 1.0, 'log-uniform'),
        'gamma': (1e-9, 0.5, 'log-uniform'),
        'min_child_weight': (0, 5),
        'n_estimators': (50, 300)}

# Setting up BayesSearchCV
opt = BayesSearchCV(reg,
                    search_spaces,
                    scoring='neg_mean_squared_error',
                    cv= 5,
                    n_iter=100,
                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault
                    return_train_score=False,
                    refit=True,                    
                    random_state=11)


# Running the optimization
time_limit = 180 # in minutes
best_params = report_perf(opt, X_train, y_train,'XGBoost',
                          callbacks=[VerboseCallback(100), 
                                     DeadlineStopper(60*time_limit)])